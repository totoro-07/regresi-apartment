# -*- coding: utf-8 -*-
"""Updated_Predictive_Analytics_Sewa_Apartment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11Wy6eOlJyZ9WyQekY2gqpioruwJub6XP

# Predictive Analytics Sewa Apartment

Nama: Ahmad Radesta

Username: ahmad007

---

## 1.Domain Proyek

Ketersediaan informasi sewa apartemen yang akurat dan relevan menjadi tantangan besar bagi calon penyewa. Dengan semakin banyaknya platform iklan properti, informasi yang tersedia seringkali tidak terstruktur, tidak lengkap, dan sulit dibandingkan antar penawaran.

> Referensi:  
> Si, R. & Lu, Min & Arikawa, Masatoshi & Asami, Yasushi & Iwasaki, J.. (2014). Finding Good Areas for Renting Apartments Using Apartments Information and Users' Trajectories. ISPRS - International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences. XL-4. 10.5194/isprsarchives-XL-4-229-2014.

> Sirmans, G. & Benjamin, John. (1991). Determinants of Market Rent. Journal of Real Estate Research. 6. 357-380.
10.1080/10835547.1991.12090653.

## 2.Business Understanding

### Problem Statements
1. Harga sewa apartemen yang tercantum di iklan seringkali tidak mencerminkan nilai pasar aktual.
2. Sulit bagi pemilik atau penyewa untuk menentukan apakah harga tersebut wajar atau tidak.

### Goals
Membangun model machine learning untuk memprediksi harga sewa apartemen berdasarkan fitur-fitur seperti lokasi, ukuran, jumlah kamar, dan deskripsi properti.


### Solution Statement
- **Ridge Regression** dan **Lasso Regression**  
  Model regresi linier dengan regularisasi (L2 dan L1) digunakan sebagai baseline. Model ini mudah diinterpretasikan dan cepat dalam pelatihan, serta mampu menangani multikolinearitas.
- **Random Forest Regressor**, **Gradient Boosting**, **XGBoost**, **CatBoost**, dan **LightGBM**  
  Kelompok model ensemble yang mampu menangkap hubungan non-linear antara fitur dan harga sewa. XGBoost dan LightGBM dikenal cepat dan akurat, sementara CatBoost menangani fitur kategori secara efisien.
- **RMSE (Root Mean Squared Error)** ‚Äì untuk mengukur kesalahan prediksi

### üîß Proses Analisis/Data Preparation
Menjalankan proses transformasi atau analisis data.
"""

!pip install catboost
!pip install lightgbm
!pip install xgboost
!pip install plotly

"""### üè∑Ô∏è One-Hot Encoding
Mengubah fitur kategorikal menjadi format numerik biner untuk modeling.
"""

import pandas as pd
import numpy as np
from typing import Tuple
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objs as go
import plotly.offline as po
from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot
from scipy.stats import probplot, boxcox
import pylab
from sklearn.feature_selection import VarianceThreshold
import collections
from sklearn.preprocessing import OrdinalEncoder
from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, cross_val_score, KFold
from sklearn.linear_model import Ridge, Lasso, BayesianRidge
from sklearn.neighbors import KNeighborsRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.svm import SVR
from catboost import CatBoostRegressor
from lightgbm import LGBMRegressor
from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error, r2_score
from scipy.special import inv_boxcox

"""## 3.Data Understanding

Dataset diambil dari [Apartments for Rent Classified](https://www.kaggle.com/datasets/adithyaawati/apartments-for-rent-classified).

**Informasi Dataset**

- File: apartments_for_rent_classified_100K.csv

### Informasi Dataset
- **File:** `apartments_for_rent_classified_100K.csv`
- **Jumlah data:** 10.000 baris
- **Fitur utama:** `price`, `bedrooms`, `bathrooms`, `size_sqft`, `location`, `description`, `category`

### Kondisi Data
- Terdapat missing value pada beberapa kolom
- Distribusi harga tidak normal (ada outlier ekstrem)

### Penjelasan Fitur
- `price`: target prediksi
- `bedrooms`, `bathrooms`, `size_sqft`: fitur numerik
- `location`, `description`: fitur kategori/teks
- `category`: jenis unit (apartment, studio, dll)

### EDA *(Rubrik Tambahan)*
- Korelasi fitur terhadap harga
- Distribusi harga berdasarkan lokasi
- Word frequency dari deskripsi properti

### üîß Proses Analisis/Data Preparation
Menjalankan proses transformasi atau analisis data.
"""

from google.colab import files
uploaded = files.upload()

"""### üîß Proses Analisis/Data Preparation
Menjalankan proses transformasi atau analisis data.
"""

!unzip archive.zip -d apartment_dataset

"""### üì• Membaca Dataset
Dataset utama dibaca ke dalam DataFrame untuk analisis lebih lanjut.
"""

df = pd.read_csv("/content/apartment_dataset/apartments_for_rent_classified_10K/apartments_for_rent_classified_10K.csv", sep=";", encoding='cp1252')

"""### üîß Proses Analisis/Data Preparation
Menjalankan proses transformasi atau analisis data.
"""

print("Jumlah data",df.shape)

"""### üîß Proses Analisis/Data Preparation
Menjalankan proses transformasi atau analisis data.
"""

df.head()

"""### üßæ Melihat Struktur Data
Menampilkan informasi umum dari dataset, seperti jumlah non-null dan tipe data.
"""

df.info()

"""| | Tipe Data | Jumlah Missing Value |
|----------|----------|----------|
|amenities|object|3549
|bathrooms|float64|34
|bedrooms|float64|7
|pets_allowed|bject|4163
|address|object|3327
|cityname|object|77
|state|object|77
|latitude|float64|10
|longitude|float64|10

### üîß Proses Analisis/Data Preparation
Menjalankan proses transformasi atau analisis data.
"""

# Menghitung jumlah kolom bertipe kategorikal dan numerik dari dataset
from typing import Tuple

def hitung_jumlah_kolom(df) -> Tuple[int, int]:
    # Ambil kolom bertipe kategorikal (objek/string)
    kolom_kategorikal = df.select_dtypes(include=['object']).columns
    jumlah_kategorikal = len(kolom_kategorikal)

    # Ambil kolom bertipe numerik
    kolom_numerik = df.select_dtypes(exclude=['object']).columns
    jumlah_numerik = len(kolom_numerik)

    return jumlah_kategorikal, jumlah_numerik

# Hitung dan tampilkan hasilnya
jumlah_kat, jumlah_num = hitung_jumlah_kolom(df)
print("Jumlah kolom kategorikal:", jumlah_kat)
print("Jumlah kolom numerik:", jumlah_num)

"""### üìä Statistik Deskriptif
Melihat ringkasan statistik numerik dari dataset.
"""

df.describe()

"""### üîß Proses Analisis/Data Preparation
Menjalankan proses transformasi atau analisis data.
"""

# Identifikasi kolom yang mengandung nilai null
kolom_dengan_null = df.columns[df.isna().any()].tolist()

# Buat DataFrame ringkasan untuk menampilkan tipe data dan jumlah nilai null pada kolom-kolom tersebut
info_null = pd.DataFrame({
    'Tipe Kolom': df[kolom_dengan_null].dtypes,
    'Total Null': df[kolom_dengan_null].isna().sum()
})

print("Daftar kolom yang mengandung nilai null dan tipe datanya:")
print(info_null)

"""### üßπ Penghapusan Kolom atau Baris
Menghapus kolom/baris yang dianggap tidak relevan atau memiliki banyak missing value.
"""

# Salin dataset untuk menjaga data asli tetap utuh
cleaned_df = df.copy()

cleaned_df = cleaned_df.dropna(subset=['bathrooms', 'bedrooms','cityname','state','latitude','longitude'])

"""### üîç Penanganan Missing Values
Mendeteksi dan/atau mengisi nilai-nilai yang hilang dalam dataset.
"""

# Mengisi nilai kosong pada kolom kategori dengan label default
cleaned_df['amenities'].fillna('tidak tersedia', inplace=True)
cleaned_df['pets_allowed'].fillna('tidak tersedia', inplace=True)
cleaned_df['address'].fillna('tidak tersedia', inplace=True)

"""### üîç Penanganan Missing Values
Mendeteksi dan/atau mengisi nilai-nilai yang hilang dalam dataset.
"""

# Identifikasi kolom yang masih memiliki nilai kosong setelah pembersihan
kolom_dengan_null = cleaned_df.columns[cleaned_df.isnull().any()].tolist()

# Buat ringkasan tipe data dan jumlah nilai null dari setiap kolom yang masih mengandung missing value
ringkasan_null = pd.DataFrame({
    'Tipe Kolom': cleaned_df[kolom_dengan_null].dtypes,
    'Total Null': cleaned_df[kolom_dengan_null].isnull().sum()
})

print("üìã Daftar kolom yang masih mengandung nilai null dan tipe datanya:")
print(ringkasan_null)
print("\nüìä Dimensi akhir dataset:", cleaned_df.shape)

"""### üîß Proses Analisis/Data Preparation
Menjalankan proses transformasi atau analisis data.
"""

# Menampilkan daftar kolom yang bertipe numerik dari dataset
kolom_numerik = cleaned_df.select_dtypes(include=['number']).columns.tolist()
print("üìà Daftar kolom bertipe numerik:")
print(kolom_numerik)

"""### ‚ö†Ô∏è Menghapus Outlier
Menggunakan metode IQR untuk membersihkan data dari nilai-nilai ekstrem.
"""

# Menentukan kolom numerik yang akan dianalisis untuk outlier
fitur_numerik = ['bathrooms', 'bedrooms', 'price', 'square_feet']

# Visualisasi boxplot untuk mendeteksi outlier pada masing-masing kolom
plt.figure(figsize=(10, 5))
for idx, fitur in enumerate(fitur_numerik, 1):
    plt.subplot(2, 4, idx)
    sns.boxplot(y=cleaned_df[fitur])
    plt.title(f'Boxplot: {fitur}')

plt.tight_layout()
plt.show()

"""| Fitur        | Outlier | Distribusi    | Rekomendasi Tambahan            |
| ------------ | ------- | ------------- | ------------------------------- |
| bathrooms    | Ya      | Skewed        | IQR atau batas atas logis       |
| bedrooms     | Ya      | Skewed        | Normalisasi atau kategorisasi   |
| price        | Ya      | Sangat skewed | Transformasi log atau trimming  |
| square\_feet | Ya      | Sangat skewed | Transformasi log dan pembatasan |

"""

#Fungsi untuk menghapus outlier
def remove_outliers_iqr(df, column):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]

#Daftar kolom yang akan diatasi outliersnya
numeric_columns = ['bathrooms', 'bedrooms', 'price','square_feet']

#Menghapus outliers dari masing-masing kolom
for column in numeric_columns:
    cleaned_df = remove_outliers_iqr(cleaned_df, column)

# Verifikasi hasil
cleaned_df.shape

#Menampilkan heatmap untuk korelasi antar fitur numerik
plt.figure(figsize=(10, 8))
numeric_columns = ['bathrooms', 'bedrooms', 'price','square_feet']
correlation_matrix = cleaned_df[numeric_columns].corr().round(2)
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

"""|                  | bathrooms | bedrooms | price | square_feet |
| ---------------- | --------- | -------- | ----- | ------------ |
| **bathrooms**    | 1.00      | 0.59     | 0.27  | 0.71         |
| **bedrooms**     | 0.59      | 1.00     | 0.18  | 0.63         |
| **price**        | 0.27      | 0.18     | 1.00  | 0.31         |
| **square_feet**  | 0.71      | 0.63     | 0.31  | 1.00         |

## 4.Data Preparation

### üîß Proses Seleksi dan Transformasi Fitur

Beberapa tahapan penting dilakukan dalam proses persiapan data untuk memastikan bahwa hanya fitur yang relevan dan informatif yang digunakan dalam pelatihan model:

- **Penghapusan Fitur Tidak Relevan**  
  Fitur-fitur yang tidak berkontribusi secara signifikan terhadap proses analisis atau prediksi dihilangkan dari dataset.

- **Encoding Variabel Kategorikal**  
  Fitur dengan tipe kategorikal diubah menjadi representasi numerik agar dapat diproses oleh algoritma machine learning.

- **Pembagian Dataset**  
  Dataset dibagi menjadi data latih dan data uji menggunakan fungsi `train_test_split` dari pustaka `scikit-learn` dengan proporsi yang seimbang.

- **Standarisasi Fitur Numerik**  
  Seluruh fitur numerik distandarisasi agar berada pada skala yang seragam, mencegah bias terhadap fitur dengan skala yang lebih besar.

---

## üóÉÔ∏è Daftar Fitur yang Dihapus

Berikut adalah fitur-fitur yang dihapus karena tidak memiliki kontribusi terhadap kualitas model atau karena bersifat redundan:

| No | Nama Fitur      | Alasan Penghapusan                                           |
|----|------------------|--------------------------------------------------------------|
| 1  | `id`             | Tidak memiliki nilai prediktif                               |
| 2  | `category`       | Nilainya sama di seluruh dataset                             |
| 3  | `title`          | Informasi teks tidak digunakan dalam model numerik          |
| 4  | `body`           | Sama seperti `title`, tidak berkontribusi dalam prediksi     |
| 5  | `currency`       | Tidak memiliki variasi (konstan)                             |
| 6  | `fee`            | Nilainya seragam                                             |
| 7  | `price_display`  | Duplikat dari fitur `price`                                  |
| 8  | `price_type`     | Tidak memiliki variasi (konstan)                             |
| 9  | `address`        | Informasi geografis tidak digunakan secara langsung          |
| 10 | `latitude`       | Dianggap tidak relevan untuk model saat ini                 |
| 11 | `longitude`      | Sama seperti `latitude`                                      |
| 12 | `time`           | Tidak memberikan kontribusi terhadap prediksi harga         |

---

> üìå Penghapusan fitur-fitur tersebut bertujuan untuk menyederhanakan model, mengurangi kompleksitas, dan fokus pada fitur-fitur yang benar-benar berdampak terhadap performa prediktif.

### üßπ Penghapusan Kolom atau Baris
Menghapus kolom/baris yang dianggap tidak relevan atau memiliki banyak missing value.
"""

features_to_drop = ['id', 'category','title', 'body','currency', 'fee','price_display','price_type','address','latitude','longitude','time']
cleaned_df = cleaned_df.drop(columns=features_to_drop)

"""### üßπ Penghapusan Kolom atau Baris
Menghapus kolom/baris yang dianggap tidak relevan atau memiliki banyak missing value.
"""

# Mengonversi kolom-kolom kategorikal menjadi representasi numerik one-hot encoding
cleaned_df = pd.concat([cleaned_df, pd.get_dummies(cleaned_df['amenities'], prefix='amenities')], axis=1)
cleaned_df = pd.concat([cleaned_df, pd.get_dummies(cleaned_df['has_photo'], prefix='has_photo')], axis=1)
cleaned_df = pd.concat([cleaned_df, pd.get_dummies(cleaned_df['pets_allowed'], prefix='pets_allowed')], axis=1)
cleaned_df = pd.concat([cleaned_df, pd.get_dummies(cleaned_df['cityname'], prefix='cityname')], axis=1)
cleaned_df = pd.concat([cleaned_df, pd.get_dummies(cleaned_df['state'], prefix='state')], axis=1)
cleaned_df = pd.concat([cleaned_df, pd.get_dummies(cleaned_df['source'], prefix='source')], axis=1)

# Menghapus kolom-kolom aslinya karena telah dikonversi menjadi bentuk numerik
cleaned_df.drop(['amenities', 'has_photo', 'pets_allowed', 'cityname', 'state', 'source'], axis=1, inplace=True)

# Menampilkan lima baris pertama dari DataFrame yang telah diproses
cleaned_df.head()

"""### üßπ Penghapusan Kolom atau Baris
Menghapus kolom/baris yang dianggap tidak relevan atau memiliki banyak missing value.
"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Misal cleaned_df sudah tersedia
X = cleaned_df.drop(["price"], axis=1)
y = cleaned_df["price"]

# Membagi data 80% train dan 20% test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)

# Standarisasi fitur numerik
numerical_features = ['bathrooms','bedrooms','square_feet']
scaler = StandardScaler()
scaler.fit(X_train[numerical_features])
X_train[numerical_features] = scaler.transform(X_train.loc[:, numerical_features])
X_train[numerical_features].head()

"""## 5.Model dan evaluasi
Proyek ini menggunakan tiga jenis model machine learning dengan tujuan yang berbeda namun saling melengkapi:

---

### 1.  Content-Based Filtering


---

### ü§ñ Melatih Model
Melatih model machine learning dengan data yang telah disiapkan.
"""

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.linear_model import Ridge, Lasso, BayesianRidge
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.svm import SVR
from sklearn.neighbors import KNeighborsRegressor
from xgboost import XGBRegressor
from catboost import CatBoostRegressor
from lightgbm import LGBMRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from tqdm import tqdm
import numpy as np
import pandas as pd

# Daftar model dengan pipeline jika perlu scaling
models = {
    'SVR': Pipeline([('scaler', StandardScaler()), ('model', SVR())]),
    'KNN': Pipeline([('scaler', StandardScaler()), ('model', KNeighborsRegressor(n_neighbors=4))]),
    'Random Forest': RandomForestRegressor(random_state=42),
    'Gradient Boosting': GradientBoostingRegressor(random_state=42),
    'XGBoost': XGBRegressor(verbosity=0, random_state=42),
    'CatBoost': CatBoostRegressor(verbose=0, random_state=42),
}

results = []

# Evaluasi setiap model
for name, model in tqdm(models.items(), desc="Training Models"):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)

    results.append({
        'Model': name,
        'RMSE': rmse,
        'MAE': mae,
        'R2 Score': r2
    })

# Tampilkan hasil evaluasi
results_df = pd.DataFrame(results).sort_values(by='RMSE', ascending=True)
print(results_df)

"""### üìè Evaluasi Model
Mengukur performa model dengan metrik seperti RMSE atau MSE.
"""

# Menampilkan hasil evaluasi
print("Hasil Evaluasi Model Regresi:\n")
print(results_df)

# (Opsional) Visualisasi perbandingan performa
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 6))
plt.bar(results_df['Model'], results_df['RMSE'], color='skyblue')
plt.title('Perbandingan RMSE Antar Model')
plt.ylabel('RMSE')
plt.xticks(rotation=45)
plt.grid(axis='y')
plt.tight_layout()
plt.show()

"""Gradient Boosting dan Random Forest memiliki performa terbaik.

Ini sejalan dengan harapan, karena model ensemble seperti ini biasanya menangkap pola kompleks dengan baik dan cocok untuk berbagai dataset.

### üîÆ Melakukan Prediksi
Menggunakan model untuk memprediksi harga berdasarkan fitur input.
"""

# Plot 1: Scatter plot (Predicted vs Actual)
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred, alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.title('Actual vs Predicted Values (Gradient Boost)')
plt.grid(True)
plt.tight_layout()
plt.show()