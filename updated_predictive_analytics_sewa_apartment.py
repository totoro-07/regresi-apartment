# -*- coding: utf-8 -*-
"""Updated_Predictive_Analytics_Sewa_Apartment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11Wy6eOlJyZ9WyQekY2gqpioruwJub6XP

# Predictive Analytics Sewa Apartment

Nama: Ahmad Radesta

Username: ahmad007

---

## 1.Domain Proyek

Ketersediaan informasi sewa apartemen yang akurat dan relevan menjadi tantangan besar bagi calon penyewa. Dengan semakin banyaknya platform iklan properti, informasi yang tersedia seringkali tidak terstruktur, tidak lengkap, dan sulit dibandingkan antar penawaran.

> Referensi:  
> Si, R. & Lu, Min & Arikawa, Masatoshi & Asami, Yasushi & Iwasaki, J.. (2014). Finding Good Areas for Renting Apartments Using Apartments Information and Users' Trajectories. ISPRS - International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences. XL-4. 10.5194/isprsarchives-XL-4-229-2014.

> Sirmans, G. & Benjamin, John. (1991). Determinants of Market Rent. Journal of Real Estate Research. 6. 357-380.
10.1080/10835547.1991.12090653.

## 2.Business Understanding

### Problem Statements
1. Harga sewa apartemen yang tercantum di iklan seringkali tidak mencerminkan nilai pasar aktual.
2. Sulit bagi pemilik atau penyewa untuk menentukan apakah harga tersebut wajar atau tidak.

### Goals
Membangun model machine learning untuk memprediksi harga sewa apartemen berdasarkan fitur-fitur seperti lokasi, ukuran, jumlah kamar, dan deskripsi properti.


### Solution Statement
- **Ridge Regression** dan **Lasso Regression**  
  Model regresi linier dengan regularisasi (L2 dan L1) digunakan sebagai baseline. Model ini mudah diinterpretasikan dan cepat dalam pelatihan, serta mampu menangani multikolinearitas.
- **Random Forest Regressor**, **Gradient Boosting**, **XGBoost**, **CatBoost**, dan **LightGBM**  
  Kelompok model ensemble yang mampu menangkap hubungan non-linear antara fitur dan harga sewa. XGBoost dan LightGBM dikenal cepat dan akurat, sementara CatBoost menangani fitur kategori secara efisien.
- **RMSE (Root Mean Squared Error)** – untuk mengukur kesalahan prediksi

### 🔧 Proses Analisis/Data Preparation
Menjalankan proses transformasi atau analisis data.
"""

!pip install catboost
!pip install lightgbm
!pip install xgboost
!pip install plotly

"""### 🏷️ One-Hot Encoding
Mengubah fitur kategorikal menjadi format numerik biner untuk modeling.
"""

import pandas as pd
import numpy as np
from typing import Tuple
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objs as go
import plotly.offline as po
from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot
from scipy.stats import probplot, boxcox
import pylab
from sklearn.feature_selection import VarianceThreshold
import collections
from sklearn.preprocessing import OrdinalEncoder
from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, cross_val_score, KFold
from sklearn.linear_model import Ridge, Lasso, BayesianRidge
from sklearn.neighbors import KNeighborsRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.svm import SVR
from catboost import CatBoostRegressor
from lightgbm import LGBMRegressor
from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error, r2_score
from scipy.special import inv_boxcox

"""## 3.Data Understanding

Dataset diambil dari [Apartments for Rent Classified](https://www.kaggle.com/datasets/adithyaawati/apartments-for-rent-classified).

**Informasi Dataset**

- File: apartments_for_rent_classified_100K.csv

### Informasi Dataset
- **File:** `apartments_for_rent_classified_100K.csv`
- **Jumlah data:** 10.000 baris
- **Fitur utama:** `price`, `bedrooms`, `bathrooms`, `size_sqft`, `location`, `description`, `category`

### Kondisi Data
- Terdapat missing value pada beberapa kolom
- Distribusi harga tidak normal (ada outlier ekstrem)

### Penjelasan Fitur
- `price`: target prediksi
- `bedrooms`, `bathrooms`, `size_sqft`: fitur numerik
- `location`, `description`: fitur kategori/teks
- `category`: jenis unit (apartment, studio, dll)

### EDA *(Rubrik Tambahan)*
- Korelasi fitur terhadap harga
- Distribusi harga berdasarkan lokasi
- Word frequency dari deskripsi properti

### 🔧 Proses Analisis/Data Preparation
Menjalankan proses transformasi atau analisis data.
"""

from google.colab import files
uploaded = files.upload()

"""### 🔧 Proses Analisis/Data Preparation
Menjalankan proses transformasi atau analisis data.
"""

!unzip archive.zip -d apartment_dataset

"""### 📥 Membaca Dataset
Dataset utama dibaca ke dalam DataFrame untuk analisis lebih lanjut.
"""

df = pd.read_csv("/content/apartment_dataset/apartments_for_rent_classified_10K/apartments_for_rent_classified_10K.csv", sep=";", encoding='cp1252')

"""### 🔧 Proses Analisis/Data Preparation
Menjalankan proses transformasi atau analisis data.
"""

print("Jumlah data",df.shape)

"""### 🔧 Proses Analisis/Data Preparation
Menjalankan proses transformasi atau analisis data.
"""

df.head()

"""### 🧾 Melihat Struktur Data
Menampilkan informasi umum dari dataset, seperti jumlah non-null dan tipe data.
"""

df.info()

"""| | Tipe Data | Jumlah Missing Value |
|----------|----------|----------|
|amenities|object|3549
|bathrooms|float64|34
|bedrooms|float64|7
|pets_allowed|bject|4163
|address|object|3327
|cityname|object|77
|state|object|77
|latitude|float64|10
|longitude|float64|10

### 🔧 Proses Analisis/Data Preparation
Menjalankan proses transformasi atau analisis data.
"""

# Menghitung jumlah kolom bertipe kategorikal dan numerik dari dataset
from typing import Tuple

def hitung_jumlah_kolom(df) -> Tuple[int, int]:
    # Ambil kolom bertipe kategorikal (objek/string)
    kolom_kategorikal = df.select_dtypes(include=['object']).columns
    jumlah_kategorikal = len(kolom_kategorikal)

    # Ambil kolom bertipe numerik
    kolom_numerik = df.select_dtypes(exclude=['object']).columns
    jumlah_numerik = len(kolom_numerik)

    return jumlah_kategorikal, jumlah_numerik

# Hitung dan tampilkan hasilnya
jumlah_kat, jumlah_num = hitung_jumlah_kolom(df)
print("Jumlah kolom kategorikal:", jumlah_kat)
print("Jumlah kolom numerik:", jumlah_num)

"""### 📊 Statistik Deskriptif
Melihat ringkasan statistik numerik dari dataset.
"""

df.describe()

"""## 4.Data Preparation

### Langkah-Langkah
- Handling missing values (median imputation untuk numerik, `'unknown'` untuk kategori)
- **Feature engineering:**
  - Ekstraksi keyword dari `description`
  - Encoding lokasi menggunakan One-Hot/Target Encoding
- Normalisasi numerik (opsional untuk model linear)

### Alasan Tahapan
- Menghindari bias dari data tidak lengkap
- Mengubah fitur teks menjadi representasi numerik
- Memastikan model dapat belajar dari representasi yang konsisten

### 🔧 Proses Analisis/Data Preparation
Menjalankan proses transformasi atau analisis data.
"""

# Identifikasi kolom yang mengandung nilai null
kolom_dengan_null = df.columns[df.isna().any()].tolist()

# Buat DataFrame ringkasan untuk menampilkan tipe data dan jumlah nilai null pada kolom-kolom tersebut
info_null = pd.DataFrame({
    'Tipe Kolom': df[kolom_dengan_null].dtypes,
    'Total Null': df[kolom_dengan_null].isna().sum()
})

print("Daftar kolom yang mengandung nilai null dan tipe datanya:")
print(info_null)

"""### 🧹 Penghapusan Kolom atau Baris
Menghapus kolom/baris yang dianggap tidak relevan atau memiliki banyak missing value.
"""

# Salin dataset untuk menjaga data asli tetap utuh
cleaned_df = df.copy()

# Hapus baris yang memiliki nilai kosong pada kolom-kolom penting karena dianggap berdampak terhadap keakuratan model
kolom_wajib = ['bathrooms', 'bedrooms', 'cityname', 'state', 'latitude', 'longitude']
cleaned_df = cleaned_df.dropna(subset=kolom_wajib)

"""### 🔍 Penanganan Missing Values
Mendeteksi dan/atau mengisi nilai-nilai yang hilang dalam dataset.
"""

# Mengisi nilai kosong pada kolom kategori dengan label default
cleaned_df['amenities'].fillna('tidak tersedia', inplace=True)
cleaned_df['pets_allowed'].fillna('tidak tersedia', inplace=True)
cleaned_df['address'].fillna('tidak tersedia', inplace=True)

"""### 🔍 Penanganan Missing Values
Mendeteksi dan/atau mengisi nilai-nilai yang hilang dalam dataset.
"""

# Identifikasi kolom yang masih memiliki nilai kosong setelah pembersihan
kolom_dengan_null = cleaned_df.columns[cleaned_df.isnull().any()].tolist()

# Buat ringkasan tipe data dan jumlah nilai null dari setiap kolom yang masih mengandung missing value
ringkasan_null = pd.DataFrame({
    'Tipe Kolom': cleaned_df[kolom_dengan_null].dtypes,
    'Total Null': cleaned_df[kolom_dengan_null].isnull().sum()
})

print("📋 Daftar kolom yang masih mengandung nilai null dan tipe datanya:")
print(ringkasan_null)
print("\n📊 Dimensi akhir dataset:", cleaned_df.shape)

"""### 🔧 Proses Analisis/Data Preparation
Menjalankan proses transformasi atau analisis data.
"""

# Menampilkan daftar kolom yang bertipe numerik dari dataset
kolom_numerik = cleaned_df.select_dtypes(include=['number']).columns.tolist()
print("📈 Daftar kolom bertipe numerik:")
print(kolom_numerik)

"""### ⚠️ Menghapus Outlier
Menggunakan metode IQR untuk membersihkan data dari nilai-nilai ekstrem.
"""

# Menentukan kolom numerik yang akan dianalisis untuk outlier
fitur_numerik = ['bathrooms', 'bedrooms', 'price', 'square_feet']

# Visualisasi boxplot untuk mendeteksi outlier pada masing-masing kolom
plt.figure(figsize=(10, 5))
for idx, fitur in enumerate(fitur_numerik, 1):
    plt.subplot(2, 4, idx)
    sns.boxplot(y=cleaned_df[fitur])
    plt.title(f'Boxplot: {fitur}')

plt.tight_layout()
plt.show()

"""| Fitur        | Outlier | Distribusi    | Rekomendasi Tambahan            |
| ------------ | ------- | ------------- | ------------------------------- |
| bathrooms    | Ya      | Skewed        | IQR atau batas atas logis       |
| bedrooms     | Ya      | Skewed        | Normalisasi atau kategorisasi   |
| price        | Ya      | Sangat skewed | Transformasi log atau trimming  |
| square\_feet | Ya      | Sangat skewed | Transformasi log dan pembatasan |

"""

#Menampilkan heatmap untuk korelasi antar fitur numerik
plt.figure(figsize=(10, 8))
numeric_columns = ['bathrooms', 'bedrooms', 'price','square_feet']
correlation_matrix = cleaned_df[numeric_columns].corr().round(2)
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

"""### ⚠️ Menghapus Outlier
Menggunakan metode IQR untuk membersihkan data dari nilai-nilai ekstrem.
"""

#Fungsi untuk menghapus outlier
def remove_outliers_iqr(df, column):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]

#Daftar kolom yang akan diatasi outliersnya
numeric_columns = ['bathrooms', 'bedrooms', 'price','square_feet']

#Menghapus outliers dari masing-masing kolom
for column in numeric_columns:
    train_df_cleaned = remove_outliers_iqr(cleaned_df, column)

# Verifikasi hasil
cleaned_df.shape

"""|                  | bathrooms | bedrooms | price | square\_feet |
| ---------------- | --------- | -------- | ----- | ------------ |
| **bathrooms**    | 1.00      | 0.71     | 0.41  | 0.80         |
| **bedrooms**     | 0.71      | 1.00     | 0.31  | 0.74         |
| **price**        | 0.41      | 0.31     | 1.00  | 0.46         |
| **square\_feet** | 0.80      | 0.74     | 0.46  | 1.00         |

**Feature Engineering**

### 🧹 Penghapusan Kolom atau Baris
Menghapus kolom/baris yang dianggap tidak relevan atau memiliki banyak missing value.
"""

features_to_drop = ['id', 'category','title', 'body','currency', 'fee','price_display','price_type','address','latitude','longitude','time']
cleaned_df = cleaned_df.drop(columns=features_to_drop)

"""### 🧹 Penghapusan Kolom atau Baris
Menghapus kolom/baris yang dianggap tidak relevan atau memiliki banyak missing value.
"""

# Mengonversi kolom-kolom kategorikal menjadi representasi numerik one-hot encoding
cleaned_df = pd.concat([cleaned_df, pd.get_dummies(cleaned_df['amenities'], prefix='amenities')], axis=1)
cleaned_df = pd.concat([cleaned_df, pd.get_dummies(cleaned_df['has_photo'], prefix='has_photo')], axis=1)
cleaned_df = pd.concat([cleaned_df, pd.get_dummies(cleaned_df['pets_allowed'], prefix='pets_allowed')], axis=1)
cleaned_df = pd.concat([cleaned_df, pd.get_dummies(cleaned_df['cityname'], prefix='cityname')], axis=1)
cleaned_df = pd.concat([cleaned_df, pd.get_dummies(cleaned_df['state'], prefix='state')], axis=1)
cleaned_df = pd.concat([cleaned_df, pd.get_dummies(cleaned_df['source'], prefix='source')], axis=1)

# Menghapus kolom-kolom aslinya karena telah dikonversi menjadi bentuk numerik
cleaned_df.drop(['amenities', 'has_photo', 'pets_allowed', 'cityname', 'state', 'source'], axis=1, inplace=True)

# Menampilkan lima baris pertama dari DataFrame yang telah diproses
cleaned_df.head()

"""### 🧹 Penghapusan Kolom atau Baris
Menghapus kolom/baris yang dianggap tidak relevan atau memiliki banyak missing value.
"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Misal cleaned_df sudah tersedia
X = cleaned_df.drop(["price"], axis=1)
y = cleaned_df["price"]

# Membagi data 80% train dan 20% test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)

# Standarisasi fitur numerik
numerical_features = ['bathrooms', 'bedrooms', 'square_feet']
scaler = StandardScaler()
scaler.fit(X_train[numerical_features])
X_train[numerical_features] = scaler.transform(X_train[numerical_features])
X_train[numerical_features].head()

"""## 5.Model dan evaluasi
Proyek ini menggunakan tiga jenis model machine learning dengan tujuan yang berbeda namun saling melengkapi:

---

### 1.  Content-Based Filtering


---

### 🔧 Proses Analisis/Data Preparation
Menjalankan proses transformasi atau analisis data.
"""

# Check for non-positive values
non_positive_values = cleaned_df['price'] <= 0
print("Number of non-positive values in 'price':", non_positive_values.sum())

"""### 🧹 Penghapusan Kolom atau Baris
Menghapus kolom/baris yang dianggap tidak relevan atau memiliki banyak missing value.
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import PowerTransformer, StandardScaler

# Pisahkan fitur dan target
X = cleaned_df.drop('price', axis=1)
y = cleaned_df['price']

# Transformasi target menggunakan PowerTransformer (Yeo-Johnson)
pt = PowerTransformer(method='yeo-johnson')
y_transformed = pt.fit_transform(y.values.reshape(-1, 1)).flatten()  # Hasil transformasi dikembalikan ke bentuk 1D

# Bagi data menjadi data latih dan data uji (80:20)
X_train, X_test, y_train, y_test = train_test_split(X, y_transformed, test_size=0.2, random_state=42)

# Standarisasi fitur numerik
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

# (Opsional) Cetak bentuk data sebagai verifikasi
print("X_train shape:", X_train.shape)
print("X_test shape:", X_test.shape)
print("y_train shape:", y_train.shape)
print("y_test shape:", y_test.shape)

"""### 🤖 Melatih Model
Melatih model machine learning dengan data yang telah disiapkan.
"""

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.linear_model import Ridge, Lasso, BayesianRidge
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.svm import SVR
from sklearn.neighbors import KNeighborsRegressor
from xgboost import XGBRegressor
from catboost import CatBoostRegressor
from lightgbm import LGBMRegressor
import numpy as np
import pandas as pd

# Daftar model
models = {
    'ridge': Ridge(),
    'xgboost': XGBRegressor(verbosity=0),
    'catboost': CatBoostRegressor(verbose=0),
    'lightgbm': LGBMRegressor(),
    'gradient boosting': GradientBoostingRegressor(),
    'lasso': Lasso(),
    'random forest': RandomForestRegressor(),
    'bayesian ridge': BayesianRidge(),
    'support vector': SVR(),
    'knn': KNeighborsRegressor(n_neighbors=4)
}

# Data evaluasi
results = []

# Training dan evaluasi masing-masing model
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)

    results.append({
        'Model': name,
        'RMSE': rmse,
        'MAE': mae,
        'R2 Score': r2
    })

# Hasil evaluasi sebagai DataFrame
results_df = pd.DataFrame(results).sort_values(by='RMSE', ascending=True)

"""### 📏 Evaluasi Model
Mengukur performa model dengan metrik seperti RMSE atau MSE.
"""

# Menampilkan hasil evaluasi
print("Hasil Evaluasi Model Regresi:\n")
print(results_df)

# (Opsional) Visualisasi perbandingan performa
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 6))
plt.bar(results_df['Model'], results_df['RMSE'], color='skyblue')
plt.title('Perbandingan RMSE Antar Model')
plt.ylabel('RMSE')
plt.xticks(rotation=45)
plt.grid(axis='y')
plt.tight_layout()
plt.show()

"""| Tujuan                      | Rekomendasi                                                                 |
| --------------------------- | --------------------------------------------------------------------------- |
| Model yang akan digunakan   | Gunakan **XGBoost** sebagai baseline terbaik untuk deployment               |
| Model pembanding (baseline) | Gunakan **Ridge** dan **Random Forest** untuk validasi model linear vs tree |
| Optimasi lebih lanjut       | Lakukan **hyperparameter tuning** pada top 3 model (XGBoost, CatBoost, RF)  |
| Model yang bisa dihapus     | Pertimbangkan untuk **tidak menggunakan Lasso dan KNN** di iterasi lanjutan |

### 🔮 Melakukan Prediksi
Menggunakan model untuk memprediksi harga berdasarkan fitur input.
"""

# Plot 1: Scatter plot (Predicted vs Actual)
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred, alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.title('Actual vs Predicted Values (XGBoost)')
plt.grid(True)
plt.tight_layout()
plt.show()